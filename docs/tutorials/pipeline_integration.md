# Pipeline Integration Tutorial

This tutorial walks through running the bundled **Nextflow** pipeline for large-scale siRNA candidate analysis and explains how it maps back to the Python entrypoints documented in {doc}`../api_reference`.

## When to Use the Pipeline

Use the Nextflow workflow when you need to:
- Score hundreds of candidate genes or transcripts in batch
- Run transcriptome + miRNA off-target analysis with BWA-MEM2
- Leverage Docker/Conda environments reproducibly on HPC or cloud infrastructure

For small jobs or interactive exploration, the CLI (`sirnaforge workflow ...`) is sufficient.

## Prerequisites

- Docker or a local conda environment with Nextflow ≥ 25.04
- 4+ CPU cores and 8 GB RAM per Nextflow task (see `nextflow_pipeline/README.md` for sizing)
- Reference FASTA files listed in `nextflow_pipeline/genomes.yaml`
- siRNA candidate FASTA/CSV generated by `sirnaforge workflow` or the Python API

> **Tip:** The Docker image `ghcr.io/austin-s-h/sirnaforge:latest` already contains Nextflow, BWA-MEM2, SAMtools, and ViennaRNA.

## Step 1 – Prepare Candidates

1. Use the CLI to generate candidates for one or more genes:
	 ```bash
	 uv run sirnaforge workflow TP53 --output-dir results/tp53 --top-n 50
	 ```
2. Collect the candidate FASTA (`sirna_candidates.fasta`) from each workflow output directory and concatenate them if you are processing multiple genes.

## Step 2 – Configure Genomes

Edit `nextflow_pipeline/genomes.yaml` to point at the transcriptome / genome references you want the pipeline to index. Example snippet:

```yaml
human:
  fasta: /data/genomes/human_GRCh38.fa
  mirna: /data/mirna/mirgenedb_human.fa
rat:
  fasta: /data/genomes/rat_mRatBN7.fa
```

If you only need a subset, comment out the others. The Nextflow modules will automatically call the functions described in `nextflow_pipeline/INTEGRATION_GUIDE.md` (e.g., `run_comprehensive_offtarget_analysis`) to perform each species-specific analysis.

## Step 3 – Run Nextflow

From the repository root:

```bash
nextflow run nextflow_pipeline/main.nf \
	--candidates results/tp53/sirna_candidates.fasta \
	--outdir nextflow_results/tp53 \
	--genome_species "human,rat"
```

Important parameters:
- `--candidates`: FASTA file with siRNA sequences (one per record)
- `--outdir`: Output directory for per-species TSV/JSON summaries
- `--genome_species`: Comma-separated list matching `genomes.yaml`
- `--max_hits`, `--bwa_k`, `--bwa_T`, `--seed_start`, `--seed_end`: Override alignment sensitivity (see pipeline config)

To run inside Docker for maximum reproducibility:

```bash
docker run --rm -it \
	-v $(pwd):/workspace -w /workspace \
	ghcr.io/austin-s-h/sirnaforge:latest \
	nextflow run nextflow_pipeline/main.nf --help
```

## Step 4 – Inspect Outputs

The pipeline mirrors the CLI output structure:

```
nextflow_results/
├── logs/
├── off_target/
│   ├── TP53_human_analysis.tsv
│   └── TP53_rat_analysis.tsv
├── sirnaforge/
│   └── manifest.json
└── workflow_summary.json
```

Each TSV/JSON pair originates from the corresponding Python entrypoints in `sirnaforge.core.off_target`. See the file `nextflow_pipeline/INTEGRATION_GUIDE.md` for the precise mapping between Nextflow modules and Python functions.

## Troubleshooting

- **Missing genome files** → verify paths in `genomes.yaml` and that containers can reach the host paths (bind mount the directories when using Docker).
- **Slow throughput** → lower `--genome_species`, reduce `--top-n` during candidate generation, or increase parallelism with `-process.maxForks` in `nextflow.config`.
- **Tool not found** → ensure you are using the provided Docker image or run `make docker-build` to rebuild locally.

## Additional Resources

- [nextflow_pipeline/INTEGRATION_GUIDE.md](https://github.com/austin-s-h/sirnaforge/blob/master/nextflow_pipeline/INTEGRATION_GUIDE.md): Deep dive into module/function boundaries
- [nextflow_pipeline/README.md](https://github.com/austin-s-h/sirnaforge/blob/master/nextflow_pipeline/README.md): Parameter reference and usage examples
- [`docs/developer/testing_guide.md`](../developer/testing_guide.md): Guidance on pipeline-related test markers

With these steps you can orchestrate the full off-target pipeline at scale while reusing the same validated Python components exposed in the API reference.
